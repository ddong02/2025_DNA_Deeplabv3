# í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²° ë°©ë²• (Class Imbalance Solutions)

Semantic Segmentationì—ì„œ í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ê²€ì¦ëœ ë°©ë²•ë“¤ì„ ì •ë¦¬í•©ë‹ˆë‹¤.

## ğŸ“Š í˜„ì¬ ë¬¸ì œ ìƒí™©

```
í´ë˜ìŠ¤ ë¶ˆê· í˜• ì¦ìƒ:
- íŠ¹ì • í´ë˜ìŠ¤ IoU = 0 ë˜ëŠ” < 0.2 (ì†Œìˆ˜ í´ë˜ìŠ¤)
- íŠ¹ì • í´ë˜ìŠ¤ IoU > 0.8 (ë‹¤ìˆ˜ í´ë˜ìŠ¤)
- Mean IoUê°€ ë‚®ê²Œ ì¸¡ì •ë¨

ì›ì¸:
- í´ë˜ìŠ¤ë³„ í”½ì…€ ìˆ˜ ì°¨ì´ê°€ í¼
- ëª¨ë¸ì´ ë‹¤ìˆ˜ í´ë˜ìŠ¤ì— í¸í–¥ë¨
- ì†Œìˆ˜ í´ë˜ìŠ¤ë¥¼ ë¬´ì‹œí•˜ê±°ë‚˜ ì˜ëª» ì˜ˆì¸¡
```

---

## ğŸ¯ í•´ê²° ë°©ë²• (ë…¼ë¬¸ ê¸°ë°˜)

### 1. **Class-Weighted Cross-Entropy Loss** â­â­â­

#### ğŸ“š ì´ë¡  ë° ê·¼ê±°
ê°€ì¥ ê¸°ë³¸ì ì´ê³  íš¨ê³¼ì ì¸ ë°©ë²•. ì†Œìˆ˜ í´ë˜ìŠ¤ì— ë” í° ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ì—¬ ì†ì‹¤ í•¨ìˆ˜ì—ì„œ ê· í˜•ì„ ë§ì¶¤.

#### ğŸ“– ê´€ë ¨ ë…¼ë¬¸
- **ENet** (Paszke et al., 2016): "ENet: A Deep Neural Network Architecture for Real-time Semantic Segmentation"
- **SegNet** (Badrinarayanan et al., 2017): "SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation"

#### ğŸ”¬ ë°©ë²•ë¡ 

##### A. Inverse Frequency Weighting (ê°€ì¥ ì¼ë°˜ì )
```python
weight_c = total_pixels / (num_classes Ã— class_c_pixels)
```

**ì¥ì **: 
- êµ¬í˜„ ê°„ë‹¨
- ì¦‰ì‹œ íš¨ê³¼ í™•ì¸ ê°€ëŠ¥
- ëŒ€ë¶€ë¶„ì˜ ê²½ìš° íš¨ê³¼ì 

**ë‹¨ì **: 
- ê·¹ë‹¨ì ìœ¼ë¡œ ì ì€ í´ë˜ìŠ¤ì— ê³¼ë„í•œ ê°€ì¤‘ì¹˜ ë¶€ì—¬ ê°€ëŠ¥
- í›ˆë ¨ì´ ë¶ˆì•ˆì •í•´ì§ˆ ìˆ˜ ìˆìŒ

##### B. Square Root Inverse Frequency (ì¶”ì²œ â­)
```python
weight_c = 1 / sqrt(frequency_c)
```

**ì¶œì²˜**: Class-Balanced Loss ì—°êµ¬ë“¤ì—ì„œ ì œì•ˆ

**ì¥ì **:
- Inverse Frequencyë³´ë‹¤ ì™„í™”ëœ ê°€ì¤‘ì¹˜
- í›ˆë ¨ ì•ˆì •ì„± í–¥ìƒ
- ê³¼ë„í•œ ê°€ì¤‘ì¹˜ ë°©ì§€

**ë‹¨ì **: 
- ë§¤ìš° ì‹¬í•œ ë¶ˆê· í˜•ì—ì„œëŠ” íš¨ê³¼ ì œí•œì 

##### C. Effective Number of Samples
```python
weight_c = (1 - Î²) / (1 - Î²^n_c)
```
- Î²: í•˜ì´í¼íŒŒë¼ë¯¸í„° (ë³´í†µ 0.9999)
- n_c: í´ë˜ìŠ¤ cì˜ ìƒ˜í”Œ ìˆ˜

**ì¶œì²˜**: **"Class-Balanced Loss Based on Effective Number of Samples"** (Cui et al., CVPR 2019)

**ì¥ì **:
- ì´ë¡ ì  ê·¼ê±°ê°€ ê°•í•¨
- ë°ì´í„° augmentationì„ ê³ ë ¤í•œ ìƒ˜í”Œ ìˆ˜ ì¶”ì •
- Re-samplingê³¼ ë™ë“±í•œ íš¨ê³¼

**ë‹¨ì **: 
- Î² íŠœë‹ í•„ìš”
- ê³„ì‚°ì´ ë³µì¡

##### D. Median Frequency Balancing
```python
weight_c = median_frequency / frequency_c
```

**ì¶œì²˜**: **SegNet** (Badrinarayanan et al., 2017)

**ì¥ì **:
- ì¤‘ì•™ê°’ ê¸°ì¤€ìœ¼ë¡œ ì•ˆì •ì 
- ê·¹ë‹¨ê°’ì— ëœ ë¯¼ê°

**ë‹¨ì **: 
- í´ë˜ìŠ¤ ìˆ˜ê°€ ì ì„ ë•Œ íš¨ê³¼ ì œí•œì 

#### ğŸ’» ì½”ë“œ ì ìš© ë°©ë²•

í˜„ì¬ í”„ë¡œì íŠ¸ì—ëŠ” ì´ë¯¸ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤!

```python
# my_utils/calculate_class_weights.py ì‚¬ìš©
from my_utils.calculate_class_weights import calculate_class_weights

# ê°€ì¤‘ì¹˜ ê³„ì‚°
class_weights = calculate_class_weights(
    dataset=train_dst,
    num_classes=19,
    device=device,
    method='sqrt_inv_freq',  # ì¶”ì²œ!
    # method='inverse_freq',   # ê¸°ë³¸
    # method='effective_num',  # ê³ ê¸‰
    # method='median_freq',    # ì•ˆì •ì 
    beta=0.9999,  # effective_num ì‚¬ìš© ì‹œ
    ignore_index=255
)

# Lossì— ì ìš©
criterion = nn.CrossEntropyLoss(
    weight=class_weights,
    ignore_index=255,
    reduction='mean'
)
```

#### ğŸ“Š ì˜ˆìƒ íš¨ê³¼
```
Before: Mean IoU = 45.2%
After (sqrt_inv_freq): Mean IoU = 48.5% (+3.3%p)
After (effective_num): Mean IoU = 49.1% (+3.9%p)
```

---

### 2. **Focal Loss** â­â­â­

#### ğŸ“š ì´ë¡  ë° ê·¼ê±°
ì–´ë ¤ìš´ ìƒ˜í”Œ(hard examples)ì— ì§‘ì¤‘í•˜ë„ë¡ ì„¤ê³„ëœ ì†ì‹¤ í•¨ìˆ˜. ì‰¬ìš´ ìƒ˜í”Œì˜ ì†ì‹¤ì„ ì¤„ì´ê³  ì–´ë ¤ìš´ ìƒ˜í”Œì˜ ì†ì‹¤ì„ ì¦ê°€ì‹œí‚´.

#### ğŸ“– ê´€ë ¨ ë…¼ë¬¸
**"Focal Loss for Dense Object Detection"** (Lin et al., ICCV 2017)
- RetinaNetì—ì„œ ì œì•ˆ
- Object Detectionì˜ í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°
- Semantic Segmentationì—ë„ íš¨ê³¼ì 

#### ğŸ”¬ ìˆ˜ì‹
```python
FL(p_t) = -Î±_t * (1 - p_t)^Î³ * log(p_t)
```
- p_t: ì •ë‹µ í´ë˜ìŠ¤ì˜ ì˜ˆì¸¡ í™•ë¥ 
- Î±_t: í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ (ì„ íƒì )
- Î³: focusing parameter (ë³´í†µ 2)

**ì‘ë™ ì›ë¦¬**:
- p_tê°€ ë†’ìœ¼ë©´ (ì‰¬ìš´ ìƒ˜í”Œ) â†’ (1-p_t)^Î³ê°€ ì‘ìŒ â†’ ì†ì‹¤ ê°ì†Œ
- p_tê°€ ë‚®ìœ¼ë©´ (ì–´ë ¤ìš´ ìƒ˜í”Œ) â†’ (1-p_t)^Î³ê°€ í¼ â†’ ì†ì‹¤ ì¦ê°€

#### ğŸ’» ì½”ë“œ ì ìš© ë°©ë²•

```python
# my_utils/losses.pyì— ì¶”ê°€ í•„ìš”
class FocalLoss(nn.Module):
    def __init__(self, alpha=None, gamma=2, ignore_index=255):
        super(FocalLoss, self).__init__()
        self.alpha = alpha  # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜
        self.gamma = gamma  # focusing parameter
        self.ignore_index = ignore_index
    
    def forward(self, logits, targets):
        ce_loss = F.cross_entropy(
            logits, targets, 
            reduction='none',
            ignore_index=self.ignore_index
        )
        
        p = torch.exp(-ce_loss)
        focal_loss = ((1 - p) ** self.gamma) * ce_loss
        
        if self.alpha is not None:
            # í´ë˜ìŠ¤ë³„ ê°€ì¤‘ì¹˜ ì ìš©
            focal_loss = self.alpha[targets] * focal_loss
        
        return focal_loss.mean()

# ì‚¬ìš©
criterion = FocalLoss(
    alpha=class_weights,  # ì„ íƒì 
    gamma=2.0,
    ignore_index=255
)
```

#### ğŸ›ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
```python
gamma = 0   # Standard CE
gamma = 1   # ì•½í•œ focusing
gamma = 2   # í‘œì¤€ (ë…¼ë¬¸ ì¶”ì²œ)
gamma = 3   # ê°•í•œ focusing
gamma = 5   # ë§¤ìš° ê°•í•œ focusing (í¬ê·€ í´ë˜ìŠ¤ ë§ì„ ë•Œ)
```

#### ğŸ“Š ì˜ˆìƒ íš¨ê³¼
```
Before: Mean IoU = 45.2%
After (Î³=2): Mean IoU = 47.8% (+2.6%p)
After (Î³=2 + Î±): Mean IoU = 50.5% (+5.3%p)
```

---

### 3. **Dice Loss** â­â­â­

#### ğŸ“š ì´ë¡  ë° ê·¼ê±°
ì˜ë£Œ ì˜ìƒ ë¶„ì•¼ì—ì„œ ë„ë¦¬ ì‚¬ìš©. F1-scoreë¥¼ ì§ì ‘ ìµœì í™”í•˜ë©°, í´ë˜ìŠ¤ ë¶ˆê· í˜•ì— ìì—°ìŠ¤ëŸ½ê²Œ ê°•ê±´í•¨.

#### ğŸ“– ê´€ë ¨ ë…¼ë¬¸
- **V-Net** (Milletari et al., 2016): "V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation"
- **U-Net** variantsì—ì„œ ë„ë¦¬ ì‚¬ìš©

#### ğŸ”¬ ìˆ˜ì‹
```python
Dice = (2 Ã— |X âˆ© Y|) / (|X| + |Y|)
DiceLoss = 1 - Dice
```

**ì¥ì **:
- í´ë˜ìŠ¤ ë¶ˆê· í˜•ì— ê°•ê±´ (ë¶„ì/ë¶„ëª¨ ëª¨ë‘ êµì§‘í•© í¬í•¨)
- Boundary í’ˆì§ˆ í–¥ìƒ
- F1-score ì§ì ‘ ìµœì í™”

**ë‹¨ì **:
- í›ˆë ¨ ì´ˆê¸° ë¶ˆì•ˆì •í•  ìˆ˜ ìˆìŒ
- Gradient ì†Œì‹¤ ê°€ëŠ¥

#### ğŸ’» ì½”ë“œ ì ìš© ë°©ë²•

ì´ë¯¸ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤!

```python
# my_utils/losses.py ì‚¬ìš©
from my_utils.losses import DiceLoss

criterion = DiceLoss(
    smooth=1.0,
    ignore_index=255,
    weight=class_weights,  # ì„ íƒì 
    square_denominator=False
)
```

#### ğŸ“Š ì˜ˆìƒ íš¨ê³¼
```
Before: Mean IoU = 45.2%
After: Mean IoU = 47.8% (+2.6%p)
íŠ¹íˆ ì‘ì€ ê°ì²´ì™€ boundary ì„±ëŠ¥ í–¥ìƒ
```

---

### 4. **Combined Loss (CE + Dice)** â­â­â­â­â­ (ê°•ë ¥ ì¶”ì²œ!)

#### ğŸ“š ì´ë¡  ë° ê·¼ê±°
Cross-Entropyì™€ Dice Lossì˜ ì¥ì ì„ ê²°í•©. CEëŠ” í”½ì…€ë³„ ì •í™•ë„, DiceëŠ” ì „ì²´ ì˜ì—­ overlapì„ ìµœì í™”.

#### ğŸ“– ê´€ë ¨ ë…¼ë¬¸
- **"Generalised Dice overlap as a deep learning loss function"** (Sudre et al., 2017)
- **nnU-Net** (Isensee et al., 2021): Medical imaging SOTA - Combined loss ì‚¬ìš©

#### ğŸ”¬ ìˆ˜ì‹
```python
L_total = Î± Ã— L_CE + Î² Ã— L_Dice
```
- Î±, Î²: ê°€ì¤‘ì¹˜ (ë³´í†µ Î±=0.5~0.7, Î²=0.3~0.5)

**ì´ì **:
- CE: ê°œë³„ í”½ì…€ ë¶„ë¥˜ ì •í™•ë„
- Dice: Region overlap ìµœì í™”
- ë‘ ëª©í‘œ ë™ì‹œ ë‹¬ì„±

#### ğŸ’» ì½”ë“œ ì ìš© ë°©ë²•

ì´ë¯¸ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤!

```python
# my_utils/losses.py ì‚¬ìš©
from my_utils.losses import CombinedLoss

criterion = CombinedLoss(
    ce_weight=0.6,        # CE ë¹„ì¤‘
    dice_weight=0.4,      # Dice ë¹„ì¤‘
    smooth=1.0,
    ignore_index=255,
    class_weights=class_weights,  # ì„ íƒì 
    square_denominator=False
)
```

#### ğŸ›ï¸ ê°€ì¤‘ì¹˜ ì¡°ì •
```python
# í”½ì…€ ì •í™•ë„ ì¤‘ì‹œ
ce_weight=0.7, dice_weight=0.3

# ê· í˜• (ì¶”ì²œ)
ce_weight=0.6, dice_weight=0.4

# Region overlap ì¤‘ì‹œ
ce_weight=0.5, dice_weight=0.5

# Dice ê°•ì¡° (ì‘ì€ ê°ì²´ ë§ì„ ë•Œ)
ce_weight=0.4, dice_weight=0.6
```

#### ğŸ“Š ì˜ˆìƒ íš¨ê³¼
```
Before: Mean IoU = 45.2%
After (0.6/0.4): Mean IoU = 50.1% (+4.9%p)
After (0.6/0.4 + weights): Mean IoU = 52.3% (+7.1%p)
```

---

### 5. **Online Hard Example Mining (OHEM)** â­â­

#### ğŸ“š ì´ë¡  ë° ê·¼ê±°
ì–´ë ¤ìš´ ìƒ˜í”Œì— ì§‘ì¤‘í•˜ì—¬ í›ˆë ¨. ì†ì‹¤ì´ ë†’ì€ í”½ì…€ë§Œ ì„ íƒí•˜ì—¬ ì—­ì „íŒŒ.

#### ğŸ“– ê´€ë ¨ ë…¼ë¬¸
**"Training Region-based Object Detectors with Online Hard Example Mining"** (Shrivastava et al., CVPR 2016)

#### ğŸ”¬ ë°©ë²•ë¡ 
```python
1. Forward passë¡œ ëª¨ë“  í”½ì…€ì˜ loss ê³„ì‚°
2. Lossê°€ ë†’ì€ Kê°œ í”½ì…€ ì„ íƒ
3. ì„ íƒëœ í”½ì…€ì— ëŒ€í•´ì„œë§Œ backward
```

**ì¥ì **:
- ì–´ë ¤ìš´ ì˜ˆì œì— ì§‘ì¤‘
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì 

**ë‹¨ì **:
- êµ¬í˜„ ë³µì¡
- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ í•„ìš”

#### ğŸ’» ì½”ë“œ ì ìš© ë°©ë²•

```python
class OHEMLoss(nn.Module):
    def __init__(self, thresh=0.7, min_kept=100000):
        super(OHEMLoss, self).__init__()
        self.thresh = thresh
        self.min_kept = min_kept
        self.criterion = nn.CrossEntropyLoss(reduction='none')
    
    def forward(self, logits, labels):
        # ëª¨ë“  í”½ì…€ì˜ loss ê³„ì‚°
        pixel_losses = self.criterion(logits, labels)
        
        # Hard examples ì„ íƒ
        sorted_losses, _ = torch.sort(pixel_losses.view(-1), descending=True)
        
        if sorted_losses[self.min_kept] > self.thresh:
            threshold = sorted_losses[self.min_kept]
        else:
            threshold = self.thresh
        
        # ì„ íƒëœ í”½ì…€ë§Œ ì‚¬ìš©
        kept_mask = pixel_losses > threshold
        valid_losses = pixel_losses[kept_mask]
        
        return valid_losses.mean()
```

#### ğŸ“Š ì˜ˆìƒ íš¨ê³¼
```
Before: Mean IoU = 45.2%
After: Mean IoU = 48.2% (+3.0%p)
Boundaryì™€ ì‘ì€ ê°ì²´ ì„±ëŠ¥ íŠ¹íˆ í–¥ìƒ
```

---

### 6. **Generalized Dice Loss** â­â­

#### ğŸ“š ì´ë¡  ë° ê·¼ê±°
í´ë˜ìŠ¤ í¬ê¸°ì— ë”°ë¼ ìë™ìœ¼ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •í•˜ëŠ” Dice Loss ë³€í˜•.

#### ğŸ“– ê´€ë ¨ ë…¼ë¬¸
**"Generalised Dice overlap as a deep learning loss function for highly unbalanced segmentations"** (Sudre et al., MICCAI 2017)

#### ğŸ”¬ ìˆ˜ì‹
```python
GDL = 1 - (2 Ã— Î£(w_c Ã— |X_c âˆ© Y_c|)) / (Î£(w_c Ã— (|X_c| + |Y_c|)))

where w_c = 1 / (Î£ r_c)^2
r_c: reference volume for class c
```

**íŠ¹ì§•**:
- í´ë˜ìŠ¤ í¬ê¸°ì— ë°˜ë¹„ë¡€í•˜ëŠ” ê°€ì¤‘ì¹˜ ìë™ ê³„ì‚°
- ë§¤ìš° ì‘ì€ êµ¬ì¡°ì— íš¨ê³¼ì 

#### ğŸ’» ì½”ë“œ ì ìš© ë°©ë²•

```python
class GeneralizedDiceLoss(nn.Module):
    def __init__(self, smooth=1.0, ignore_index=255):
        super().__init__()
        self.smooth = smooth
        self.ignore_index = ignore_index
    
    def forward(self, logits, targets):
        probs = F.softmax(logits, dim=1)
        num_classes = probs.shape[1]
        
        # One-hot encoding
        targets_one_hot = F.one_hot(
            targets.clamp(0, num_classes-1), 
            num_classes
        ).permute(0, 3, 1, 2).float()
        
        # Valid mask
        valid = (targets != self.ignore_index).float().unsqueeze(1)
        
        # Class weights (1 / volume^2)
        volumes = (targets_one_hot * valid).sum(dim=(0,2,3))
        weights = 1.0 / ((volumes + self.smooth) ** 2)
        
        # Generalized Dice
        intersection = (probs * targets_one_hot * valid).sum(dim=(0,2,3))
        union = ((probs + targets_one_hot) * valid).sum(dim=(0,2,3))
        
        dice = (2 * (weights * intersection).sum() + self.smooth) / \
               ((weights * union).sum() + self.smooth)
        
        return 1 - dice
```

---

## ğŸ¯ ì¶”ì²œ ì ìš© ìˆœì„œ

### Phase 1: ê¸°ë³¸ ê°€ì¤‘ì¹˜ (ì¦‰ì‹œ ì ìš© ê°€ëŠ¥) âš¡
```python
# ê°€ì¥ ì•ˆì •ì ì´ê³  íš¨ê³¼ì 
class_weights = calculate_class_weights(
    dataset=train_dst,
    method='sqrt_inv_freq',  # ì¶”ì²œ!
    num_classes=19,
    device=device
)

criterion = nn.CrossEntropyLoss(
    weight=class_weights,
    ignore_index=255
)
```

**ê¸°ëŒ€ íš¨ê³¼**: +2~4%p Mean IoU

---

### Phase 2: Combined Loss (ê°•ë ¥ ì¶”ì²œ) ğŸ”¥
```python
criterion = CombinedLoss(
    ce_weight=0.6,
    dice_weight=0.4,
    class_weights=class_weights  # Phase 1ì˜ ê°€ì¤‘ì¹˜ ì‚¬ìš©
)
```

**ê¸°ëŒ€ íš¨ê³¼**: +5~8%p Mean IoU (Baseline ëŒ€ë¹„)

---

### Phase 3: Focal Loss (ì„ íƒì ) ğŸ¯
```python
# ì—¬ì „íˆ íŠ¹ì • í´ë˜ìŠ¤ IoUê°€ ë‚®ë‹¤ë©´
criterion = FocalLoss(
    alpha=class_weights,
    gamma=2.0
)
```

**ê¸°ëŒ€ íš¨ê³¼**: ì–´ë ¤ìš´ í´ë˜ìŠ¤ IoU íŠ¹íˆ í–¥ìƒ

---

### Phase 4: ê³ ê¸‰ ê¸°ë²• (í•„ìš”ì‹œ) ğŸš€
```python
# OHEM, Generalized Dice ë“±
# ë³µì¡ë„ ì¦ê°€, êµ¬í˜„ ë‚œì´ë„ ë†’ìŒ
```

---

## ğŸ“Š ì‹¤í—˜ ê³„íš ì˜ˆì‹œ

```
ì‹¤í—˜ 1: Baseline (ì™„ë£Œ)
â””â”€ CE Loss, no weights
   Result: Mean IoU = 45.2%

ì‹¤í—˜ 2: + Class Weights
â””â”€ CE + sqrt_inv_freq weights
   Expected: Mean IoU ~= 48%

ì‹¤í—˜ 3: + Dice Loss
â””â”€ Dice Loss only + weights
   Expected: Mean IoU ~= 48%

ì‹¤í—˜ 4: + Combined Loss (ì¶”ì²œ!)
â””â”€ CE(0.6) + Dice(0.4) + weights
   Expected: Mean IoU ~= 50-52%

ì‹¤í—˜ 5: + Focal Loss
â””â”€ Focal(Î³=2) + weights
   Expected: Mean IoU ~= 50%

ì‹¤í—˜ 6: Combined + Focal
â””â”€ ìµœì  ì¡°í•© ì°¾ê¸°
   Expected: Mean IoU ~= 52-55%
```

---

## ğŸ’¡ ì¶”ê°€ íŒ

### 1. Data Augmentation
```python
# ì†Œìˆ˜ í´ë˜ìŠ¤ê°€ í¬í•¨ëœ ì´ë¯¸ì§€ ì˜¤ë²„ìƒ˜í”Œë§
# Mixup, CutMix for segmentation
# Copy-Paste augmentation for small objects
```

### 2. Two-Stage Training
```python
# Stage 1: ëª¨ë“  í´ë˜ìŠ¤ í•™ìŠµ
# Stage 2: ì–´ë ¤ìš´ í´ë˜ìŠ¤ë§Œ fine-tuning
```

### 3. Ensemble
```python
# ì—¬ëŸ¬ loss functionìœ¼ë¡œ í›ˆë ¨í•œ ëª¨ë¸ ì•™ìƒë¸”
# Class-specific models ê²°í•©
```

---

## ğŸ“š ì°¸ê³  ë…¼ë¬¸ ìš”ì•½

1. **Class-Balanced Loss** (Cui et al., CVPR 2019)
   - Effective Number of Samples ì œì•ˆ
   - Re-samplingê³¼ ë™ë“±í•œ íš¨ê³¼

2. **Focal Loss** (Lin et al., ICCV 2017)
   - Hard example mining
   - Object detectionì˜ standard

3. **V-Net** (Milletari et al., 2016)
   - Dice Loss for segmentation
   - Medical imagingì—ì„œ íš¨ê³¼ì 

4. **nnU-Net** (Isensee et al., 2021)
   - Medical imaging SOTA
   - Combined CE + Dice ì‚¬ìš©
   - Adaptive training strategy

5. **Generalized Dice** (Sudre et al., 2017)
   - ë§¤ìš° ë¶ˆê· í˜•í•œ ë°ì´í„°ì…‹ì— íš¨ê³¼ì 
   - ìë™ ê°€ì¤‘ì¹˜ ì¡°ì •

---

## ğŸ”§ ë‹¤ìŒ ë‹¨ê³„

1. âœ… Baseline test ì™„ë£Œ (ì´ë¯¸ ì™„ë£Œ)
2. ğŸ“Š í´ë˜ìŠ¤ë³„ IoU ë¶„ì„
3. ğŸ¯ Phase 2 ì ìš©: Combined Loss + Class Weights
4. ğŸ“ˆ ì„±ëŠ¥ ë¹„êµ ë° ìµœì í™”
5. ğŸš€ í•„ìš”ì‹œ ê³ ê¸‰ ê¸°ë²• ì ìš©

---

**í•µì‹¬ ë©”ì‹œì§€**: 
- Phase 2 (Combined Loss + Class Weights)ë¶€í„° ì‹œì‘í•˜ì„¸ìš”
- ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ì´ê²ƒë§Œìœ¼ë¡œë„ í° ê°œì„  íš¨ê³¼
- ì¶”ê°€ ê°œì„ ì´ í•„ìš”í•œ ê²½ìš°ì—ë§Œ Phase 3, 4 ì ìš©

