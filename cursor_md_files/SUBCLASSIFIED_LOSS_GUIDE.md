# Subclassified Loss: ì„œë¸Œí´ë˜ìŠ¤ ê´€ì ì˜ ë°ì´í„° ë¶ˆê· í˜• í•´ê²°

## ğŸ“š ë…¼ë¬¸ ì •ë³´

**ì œëª©**: "Subclassified Loss: Rethinking Data Imbalance From Subclass Perspective for Semantic Segmentation"

**í•µì‹¬ ì•„ì´ë””ì–´**: í´ë˜ìŠ¤ ê°„ ë¶ˆê· í˜•ë¿ë§Œ ì•„ë‹ˆë¼ **í´ë˜ìŠ¤ ë‚´ë¶€ì˜ ë‹¤ì–‘ì„±(intra-class diversity)**ì„ ê³ ë ¤í•œ ìƒˆë¡œìš´ ì ‘ê·¼

---

## ğŸ¯ ê¸°ì¡´ ë°©ë²•ê³¼ì˜ ì°¨ì´ì 

### ê¸°ì¡´ ë°©ë²•ë“¤ (Inter-class ë¶ˆê· í˜•)
```
í´ë˜ìŠ¤ ê´€ì :
Car (ë§ìŒ) â”€â”€â”€â–º ê°€ì¤‘ì¹˜ ë‚®ìŒ
Pedestrian (ì ìŒ) â”€â”€â”€â–º ê°€ì¤‘ì¹˜ ë†’ìŒ

ë¬¸ì œì :
- ê°™ì€ í´ë˜ìŠ¤ ë‚´ì—ì„œë„ ë‹¤ì–‘í•œ ìƒí™©ì´ ì¡´ì¬
- ì˜ˆ: Car í´ë˜ìŠ¤
  â”œâ”€ ê°€ê¹Œìš´ í° ì°¨ (ì‰¬ì›€, ë§ìŒ)
  â””â”€ ë¨¼ ì‘ì€ ì°¨ (ì–´ë ¤ì›€, ì ìŒ)
```

### Subclassified Loss (Intra-class ë¶ˆê· í˜•)
```
ì„œë¸Œí´ë˜ìŠ¤ ê´€ì :
Car í´ë˜ìŠ¤
â”œâ”€ Subclass 1: í° ì°¨, ê°€ê¹Œìš´ ì°¨ (ì‰¬ì›€) â”€â”€â”€â–º ê°€ì¤‘ì¹˜ ë‚®ìŒ
â”œâ”€ Subclass 2: ì¤‘ê°„ ì°¨ (ë³´í†µ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º ê°€ì¤‘ì¹˜ ë³´í†µ
â””â”€ Subclass 3: ì‘ì€ ì°¨, ë¨¼ ì°¨ (ì–´ë ¤ì›€) â”€â”€â”€â–º ê°€ì¤‘ì¹˜ ë†’ìŒ

ì¥ì :
- í´ë˜ìŠ¤ ë‚´ì˜ ì„¸ë¶€ ìƒí™©ì„ êµ¬ë¶„
- ë” ì •êµí•œ ê°€ì¤‘ì¹˜ ì¡°ì •
- ì–´ë ¤ìš´ ìƒí™©ì— ì§‘ì¤‘
```

---

## ğŸ”¬ ë°©ë²•ë¡ 

### 1. ì„œë¸Œí´ë˜ìŠ¤ ì •ì˜ (Subclass Identification)

#### A. Feature Map ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§
```python
ê° í´ë˜ìŠ¤ cì— ëŒ€í•´:
1. Feature mapì—ì„œ í´ë˜ìŠ¤ cì— ì†í•˜ëŠ” í”½ì…€ë“¤ì˜ íŠ¹ì§• ì¶”ì¶œ
2. íŠ¹ì§• ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ Kê°œì˜ ì„œë¸Œí´ë˜ìŠ¤ë¡œ í´ëŸ¬ìŠ¤í„°ë§
3. ê° ì„œë¸Œí´ë˜ìŠ¤ëŠ” íŠ¹ì • ìƒí™©/ë‚œì´ë„ë¥¼ ëŒ€í‘œ

ì˜ˆì‹œ (Car í´ë˜ìŠ¤):
- Subclass 1: í° ì°¨ (feature: ë†’ì€ confidence, í° ì˜ì—­)
- Subclass 2: ì¤‘ê°„ ì°¨ (feature: ì¤‘ê°„ confidence, ì¤‘ê°„ ì˜ì—­)
- Subclass 3: ì‘ì€/íìƒ‰ëœ ì°¨ (feature: ë‚®ì€ confidence, ì‘ì€ ì˜ì—­)
```

#### B. ìë™ í•™ìŠµ ê°€ëŠ¥
```python
ì„œë¸Œí´ë˜ìŠ¤ í• ë‹¹ì€ í•™ìŠµ ì¤‘ ìë™ìœ¼ë¡œ ê°±ì‹ :
- ì´ˆê¸°: ëœë¤ ë˜ëŠ” K-means ì´ˆê¸°í™”
- í•™ìŠµ ì¤‘: Feature similarity ê¸°ë°˜ ì—…ë°ì´íŠ¸
- ê²°ê³¼: ìì—°ìŠ¤ëŸ½ê²Œ ë‚œì´ë„ë³„ë¡œ ê·¸ë£¹í™”
```

### 2. ì„œë¸Œí´ë˜ìŠ¤ë³„ ê°€ì¤‘ì¹˜ ê³„ì‚°

#### A. ë¶„í¬ ê¸°ë°˜ ê°€ì¤‘ì¹˜
```python
w_sc = f(frequency_sc, difficulty_sc)

where:
- frequency_sc: ì„œë¸Œí´ë˜ìŠ¤ scì˜ ì¶œí˜„ ë¹ˆë„
- difficulty_sc: ì„œë¸Œí´ë˜ìŠ¤ scì˜ í•™ìŠµ ë‚œì´ë„ (loss ê¸°ë°˜)

êµ¬ì²´ì  ê³„ì‚°:
w_sc = (1 / frequency_sc) Ã— (avg_loss_sc / overall_avg_loss)
```

#### B. ì ì‘ì  ê°€ì¤‘ì¹˜ ì¡°ì •
```python
í•™ìŠµ ì§„í–‰ì— ë”°ë¼ ë™ì  ì¡°ì •:
- ì´ˆê¸°: ë¹ˆë„ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì¤‘ì‹¬
- ì¤‘ê¸°: ë‚œì´ë„ ìš”ì†Œ ì ì§„ì  ì¶”ê°€
- í›„ê¸°: ì–´ë ¤ìš´ ì„œë¸Œí´ë˜ìŠ¤ì— ì§‘ì¤‘
```

### 3. ì†ì‹¤ í•¨ìˆ˜ í†µí•©

#### A. Subclassified Cross-Entropy Loss
```python
L_SCE = -Î£_i Î£_c Î£_sc w_sc Â· y_i^c Â· Î´(sc_i = sc) Â· log(p_i^c)

where:
- i: í”½ì…€ ì¸ë±ìŠ¤
- c: í´ë˜ìŠ¤
- sc: ì„œë¸Œí´ë˜ìŠ¤
- w_sc: ì„œë¸Œí´ë˜ìŠ¤ ê°€ì¤‘ì¹˜
- Î´(sc_i = sc): í”½ì…€ iê°€ ì„œë¸Œí´ë˜ìŠ¤ scì— ì†í•˜ëŠ”ì§€ ì—¬ë¶€
- p_i^c: í´ë˜ìŠ¤ cì˜ ì˜ˆì¸¡ í™•ë¥ 
```

#### B. ê¸°ì¡´ Lossì™€ì˜ í˜¸í™˜ì„±
```python
# Standard CEë¡œ ì¶•ì†Œ ê°€ëŠ¥
K = 1 (ì„œë¸Œí´ë˜ìŠ¤ 1ê°œ) â†’ Standard CE

# Class-weighted CEë¡œ ì¶•ì†Œ ê°€ëŠ¥
K = 1, w_sc = class_weights â†’ Weighted CE

# ìœ ì—°í•œ í†µí•©
L_total = Î± Â· L_SCE + Î² Â· L_CE + Î³ Â· L_Dice
```

---

## ğŸ’» êµ¬í˜„ ë°©ë²•

### Option 1: ë‹¨ìˆœ ë²„ì „ (K-means ê¸°ë°˜)

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from sklearn.cluster import KMeans

class SubclassifiedLoss(nn.Module):
    def __init__(self, num_classes, num_subclasses=3, 
                 ignore_index=255, update_freq=100):
        super().__init__()
        self.num_classes = num_classes
        self.num_subclasses = num_subclasses
        self.ignore_index = ignore_index
        self.update_freq = update_freq
        
        # ì„œë¸Œí´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”
        self.register_buffer(
            'subclass_weights',
            torch.ones(num_classes, num_subclasses)
        )
        
        # ì„œë¸Œí´ë˜ìŠ¤ í• ë‹¹ (í´ë˜ìŠ¤ë³„ K-means centroid)
        self.register_buffer(
            'subclass_centroids',
            torch.randn(num_classes, num_subclasses, 256)  # feature dim
        )
        
        self.iter_count = 0
    
    def assign_subclasses(self, features, targets):
        """
        íŠ¹ì§•ë§µ ê¸°ë°˜ìœ¼ë¡œ ê° í”½ì…€ì„ ì„œë¸Œí´ë˜ìŠ¤ì— í• ë‹¹
        """
        B, C, H, W = features.shape
        features_flat = features.permute(0, 2, 3, 1).reshape(-1, C)
        targets_flat = targets.view(-1)
        
        subclass_assignment = torch.zeros_like(targets_flat)
        
        for c in range(self.num_classes):
            # í´ë˜ìŠ¤ cì— ì†í•˜ëŠ” í”½ì…€ ë§ˆìŠ¤í¬
            mask = (targets_flat == c)
            if mask.sum() == 0:
                continue
            
            # í•´ë‹¹ í´ë˜ìŠ¤ì˜ íŠ¹ì§• ì¶”ì¶œ
            class_features = features_flat[mask]
            
            # ì„œë¸Œí´ë˜ìŠ¤ í• ë‹¹ (centroidì™€ì˜ ê±°ë¦¬ ê¸°ë°˜)
            distances = torch.cdist(
                class_features,
                self.subclass_centroids[c]
            )
            subclass_ids = distances.argmin(dim=1)
            
            subclass_assignment[mask] = subclass_ids
        
        return subclass_assignment.view(B, H, W)
    
    def update_weights(self, losses, targets, subclass_assignment):
        """
        ì„œë¸Œí´ë˜ìŠ¤ë³„ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
        """
        for c in range(self.num_classes):
            for sc in range(self.num_subclasses):
                # í•´ë‹¹ ì„œë¸Œí´ë˜ìŠ¤ ë§ˆìŠ¤í¬
                mask = (targets == c) & (subclass_assignment == sc)
                
                if mask.sum() == 0:
                    continue
                
                # ë¹ˆë„ ê¸°ë°˜ ê°€ì¤‘ì¹˜
                frequency = mask.float().mean()
                
                # ë‚œì´ë„ ê¸°ë°˜ ê°€ì¤‘ì¹˜ (í‰ê·  loss)
                avg_loss = losses[mask].mean()
                overall_avg = losses[targets != self.ignore_index].mean()
                
                # ê²°í•© ê°€ì¤‘ì¹˜
                freq_weight = 1.0 / (frequency + 1e-6)
                diff_weight = avg_loss / (overall_avg + 1e-6)
                
                self.subclass_weights[c, sc] = freq_weight * diff_weight
        
        # ì •ê·œí™”
        self.subclass_weights = F.normalize(
            self.subclass_weights, p=1, dim=1
        ) * self.num_subclasses
    
    def forward(self, logits, targets, features=None):
        """
        features: ë„¤íŠ¸ì›Œí¬ ì¤‘ê°„ì¸µì˜ íŠ¹ì§•ë§µ (B, C, H, W)
        """
        # Standard CE ê³„ì‚°
        pixel_losses = F.cross_entropy(
            logits, targets,
            ignore_index=self.ignore_index,
            reduction='none'
        )
        
        # ì„œë¸Œí´ë˜ìŠ¤ í• ë‹¹
        if features is not None and self.iter_count % self.update_freq == 0:
            with torch.no_grad():
                subclass_assignment = self.assign_subclasses(features, targets)
                self.update_weights(pixel_losses, targets, subclass_assignment)
        else:
            # ì´ì „ í• ë‹¹ ì‚¬ìš© (íš¨ìœ¨ì„±)
            subclass_assignment = self.assign_subclasses(features, targets)
        
        # ì„œë¸Œí´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©
        weights = torch.ones_like(pixel_losses)
        for c in range(self.num_classes):
            for sc in range(self.num_subclasses):
                mask = (targets == c) & (subclass_assignment == sc)
                weights[mask] = self.subclass_weights[c, sc]
        
        # ê°€ì¤‘ ì†ì‹¤
        weighted_loss = (pixel_losses * weights).mean()
        
        self.iter_count += 1
        return weighted_loss
```

### Option 2: ê³ ê¸‰ ë²„ì „ (ì˜¨ë¼ì¸ í´ëŸ¬ìŠ¤í„°ë§)

```python
class AdaptiveSubclassifiedLoss(nn.Module):
    """
    í•™ìŠµ ì¤‘ ë™ì ìœ¼ë¡œ ì„œë¸Œí´ë˜ìŠ¤ ì—…ë°ì´íŠ¸
    """
    def __init__(self, num_classes, num_subclasses=3, 
                 momentum=0.9, ignore_index=255):
        super().__init__()
        self.num_classes = num_classes
        self.num_subclasses = num_subclasses
        self.momentum = momentum
        self.ignore_index = ignore_index
        
        # Moving average of subclass centroids
        self.register_buffer(
            'subclass_centroids',
            torch.randn(num_classes, num_subclasses, 256)
        )
        
        # Moving average of subclass statistics
        self.register_buffer(
            'subclass_counts',
            torch.zeros(num_classes, num_subclasses)
        )
        
        self.register_buffer(
            'subclass_losses',
            torch.zeros(num_classes, num_subclasses)
        )
    
    def update_centroids(self, features, targets, subclass_assignment):
        """
        Exponential moving averageë¡œ centroid ì—…ë°ì´íŠ¸
        """
        B, C, H, W = features.shape
        features_flat = features.permute(0, 2, 3, 1).reshape(-1, C)
        targets_flat = targets.view(-1)
        subclass_flat = subclass_assignment.view(-1)
        
        for c in range(self.num_classes):
            for sc in range(self.num_subclasses):
                mask = (targets_flat == c) & (subclass_flat == sc)
                if mask.sum() == 0:
                    continue
                
                # í˜„ì¬ ë°°ì¹˜ì˜ í‰ê·  íŠ¹ì§•
                current_centroid = features_flat[mask].mean(dim=0)
                
                # EMA ì—…ë°ì´íŠ¸
                self.subclass_centroids[c, sc] = \
                    self.momentum * self.subclass_centroids[c, sc] + \
                    (1 - self.momentum) * current_centroid
    
    def compute_weights(self):
        """
        ì„œë¸Œí´ë˜ìŠ¤ í†µê³„ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ê³„ì‚°
        """
        # ë¹ˆë„ ì—­ìˆ˜
        freq_weights = 1.0 / (self.subclass_counts + 1e-6)
        
        # ë‚œì´ë„ (í‰ê·  loss)
        avg_losses = self.subclass_losses / (self.subclass_counts + 1e-6)
        overall_avg = avg_losses.mean()
        diff_weights = avg_losses / (overall_avg + 1e-6)
        
        # ê²°í•©
        weights = freq_weights * diff_weights
        
        # í´ë˜ìŠ¤ë³„ ì •ê·œí™”
        weights = F.normalize(weights, p=1, dim=1) * self.num_subclasses
        
        return weights
    
    def forward(self, logits, targets, features):
        # í”½ì…€ë³„ loss ê³„ì‚°
        pixel_losses = F.cross_entropy(
            logits, targets,
            ignore_index=self.ignore_index,
            reduction='none'
        )
        
        # ì„œë¸Œí´ë˜ìŠ¤ í• ë‹¹ (ê°€ì¥ ê°€ê¹Œìš´ centroid)
        with torch.no_grad():
            B, C, H, W = features.shape
            features_flat = features.permute(0, 2, 3, 1).reshape(-1, C)
            targets_flat = targets.view(-1)
            
            subclass_assignment = torch.zeros_like(targets_flat)
            
            for c in range(self.num_classes):
                mask = (targets_flat == c)
                if mask.sum() == 0:
                    continue
                
                distances = torch.cdist(
                    features_flat[mask],
                    self.subclass_centroids[c]
                )
                subclass_assignment[mask] = distances.argmin(dim=1)
            
            subclass_assignment = subclass_assignment.view(B, H, W)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            for c in range(self.num_classes):
                for sc in range(self.num_subclasses):
                    mask = (targets == c) & (subclass_assignment == sc)
                    if mask.sum() > 0:
                        self.subclass_counts[c, sc] = \
                            self.momentum * self.subclass_counts[c, sc] + \
                            (1 - self.momentum) * mask.float().sum()
                        
                        self.subclass_losses[c, sc] = \
                            self.momentum * self.subclass_losses[c, sc] + \
                            (1 - self.momentum) * pixel_losses[mask].mean()
            
            # Centroid ì—…ë°ì´íŠ¸
            self.update_centroids(features, targets, subclass_assignment)
        
        # ê°€ì¤‘ì¹˜ ê³„ì‚° ë° ì ìš©
        weights_matrix = self.compute_weights()
        
        weights = torch.ones_like(pixel_losses)
        for c in range(self.num_classes):
            for sc in range(self.num_subclasses):
                mask = (targets == c) & (subclass_assignment == sc)
                weights[mask] = weights_matrix[c, sc]
        
        weighted_loss = (pixel_losses * weights).mean()
        
        return weighted_loss
```

---

## ğŸ¯ ì‚¬ìš© ë°©ë²•

### 1. ë„¤íŠ¸ì›Œí¬ ìˆ˜ì • í•„ìš”

```python
class DeepLabV3WithFeatures(nn.Module):
    """
    ì¤‘ê°„ íŠ¹ì§•ë§µì„ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •
    """
    def __init__(self, original_model):
        super().__init__()
        self.model = original_model
        self.features = None
        
        # Feature hook ë“±ë¡
        def hook(module, input, output):
            self.features = output
        
        # ASPP ì´í›„ì˜ íŠ¹ì§• ì¶”ì¶œ
        self.model.classifier[0].register_forward_hook(hook)
    
    def forward(self, x):
        logits = self.model(x)
        return logits, self.features
```

### 2. í›ˆë ¨ ë£¨í”„ ìˆ˜ì •

```python
# ëª¨ë¸ ì´ˆê¸°í™”
model = DeepLabV3WithFeatures(original_model)

# Loss ì´ˆê¸°í™”
criterion = SubclassifiedLoss(
    num_classes=19,
    num_subclasses=3,  # í´ë˜ìŠ¤ë‹¹ 3ê°œ ì„œë¸Œí´ë˜ìŠ¤
    ignore_index=255
)

# í›ˆë ¨
for images, labels in train_loader:
    optimizer.zero_grad()
    
    # Forward (íŠ¹ì§•ë§µë„ ë°˜í™˜)
    logits, features = model(images)
    
    # Subclassified Loss ê³„ì‚°
    loss = criterion(logits, labels, features)
    
    loss.backward()
    optimizer.step()
```

---

## ğŸ“Š ì‹¤í—˜ ê²°ê³¼ (ë…¼ë¬¸)

### SemanticKITTI (LiDAR)
```
Method              | mIoU
--------------------|-------
Standard CE         | 59.3%
Focal Loss          | 60.1%
Class-weighted CE   | 60.8%
Subclassified Loss  | 62.7%  (+3.4%p)
```

### Cityscapes (Image)
```
Method              | mIoU
--------------------|-------
Standard CE         | 78.2%
Class-weighted CE   | 78.9%
Subclassified Loss  | 80.1%  (+1.9%p)
```

### íŠ¹ì§•
- **ì†Œìˆ˜ í´ë˜ìŠ¤ ê°œì„ **: IoU 0ì— ê°€ê¹Œìš´ í´ë˜ìŠ¤ë“¤ì˜ ì„±ëŠ¥ í¬ê²Œ í–¥ìƒ
- **ì–´ë ¤ìš´ ìƒí™© ê°œì„ **: ì‘ì€ ê°ì²´, íìƒ‰ëœ ê°ì²´ ì„±ëŠ¥ í–¥ìƒ
- **í”ŒëŸ¬ê·¸ì¸ ê°€ëŠ¥**: ê¸°ì¡´ ë„¤íŠ¸ì›Œí¬ì™€ ì‰½ê²Œ í†µí•©

---

## ğŸ’¡ ì¥ë‹¨ì 

### ì¥ì  âœ…

1. **ì„¸ë°€í•œ ë¶ˆê· í˜• í•´ê²°**
   - í´ë˜ìŠ¤ ë‚´ë¶€ì˜ ë‹¤ì–‘ì„± ê³ ë ¤
   - ì–´ë ¤ìš´ ìƒí™©ì— ìë™ìœ¼ë¡œ ì§‘ì¤‘

2. **ì ì‘ì  í•™ìŠµ**
   - í•™ìŠµ ì¤‘ ì„œë¸Œí´ë˜ìŠ¤ ìë™ ë°œê²¬
   - ë™ì  ê°€ì¤‘ì¹˜ ì¡°ì •

3. **í˜¸í™˜ì„±**
   - ê¸°ì¡´ ì•„í‚¤í…ì²˜ì™€ í˜¸í™˜
   - ë‹¤ë¥¸ lossì™€ ê²°í•© ê°€ëŠ¥

4. **ê²€ì¦ëœ íš¨ê³¼**
   - SemanticKITTI, Cityscapesì—ì„œ ê²€ì¦
   - ë‹¤ì–‘í•œ ë°±ë³¸ì—ì„œ íš¨ê³¼ í™•ì¸

### ë‹¨ì  âŒ

1. **ê³„ì‚° ë³µì¡ë„**
   - íŠ¹ì§•ë§µ ì¶”ì¶œ ë° í´ëŸ¬ìŠ¤í„°ë§ í•„ìš”
   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€

2. **í•˜ì´í¼íŒŒë¼ë¯¸í„°**
   - num_subclasses íŠœë‹ í•„ìš”
   - update_freq, momentum ì„¤ì • í•„ìš”

3. **êµ¬í˜„ ë³µì¡ë„**
   - ë„¤íŠ¸ì›Œí¬ ìˆ˜ì • í•„ìš”
   - í›ˆë ¨ ë£¨í”„ ë³€ê²½ í•„ìš”

4. **ì´ˆê¸° ë¶ˆì•ˆì •**
   - ì´ˆê¸° ì„œë¸Œí´ë˜ìŠ¤ í• ë‹¹ì´ ëœë¤
   - Warm-up í•„ìš”í•  ìˆ˜ ìˆìŒ

---

## ğŸ”§ ì‹¤ì „ ì ìš© íŒ

### 1. ë‹¨ê³„ì  ì ìš©
```python
# Phase 1: ê°„ë‹¨í•œ ë²„ì „ë¶€í„°
num_subclasses = 2  # ì‰¬ì›€/ì–´ë ¤ì›€ë§Œ êµ¬ë¶„

# Phase 2: ì„¸ë¶„í™”
num_subclasses = 3  # ì‰¬ì›€/ì¤‘ê°„/ì–´ë ¤ì›€

# Phase 3: ìµœì í™”
num_subclasses = 5  # ë” ì„¸ë°€í•œ êµ¬ë¶„
```

### 2. ê¸°ì¡´ Lossì™€ ê²°í•©
```python
# Combined approach
L_total = 0.5 * L_CE + 0.3 * L_Dice + 0.2 * L_Subclassified
```

### 3. í´ë˜ìŠ¤ë³„ ì„œë¸Œí´ë˜ìŠ¤ ìˆ˜ ì¡°ì •
```python
# ë³µì¡í•œ í´ë˜ìŠ¤ëŠ” ë” ë§ì€ ì„œë¸Œí´ë˜ìŠ¤
subclass_config = {
    'car': 5,        # ë‹¤ì–‘í•œ í¬ê¸°/ê±°ë¦¬
    'pedestrian': 4, # ë‹¤ì–‘í•œ í¬ì¦ˆ
    'road': 2,       # ë¹„êµì  ë‹¨ìˆœ
    'sky': 1         # ë§¤ìš° ë‹¨ìˆœ
}
```

---

## ğŸ¯ ì¶”ì²œ ì‚¬í•­

### ë‹¹ì‹ ì˜ ìƒí™©ì— ì í•©í•œê°€?

**YES, ë‹¤ìŒ ê²½ìš° ì‹œë„í•´ë³¼ ê°€ì¹˜:**
1. âœ… í´ë˜ìŠ¤ë³„ IoU í¸ì°¨ê°€ ë§¤ìš° í¼ (0 ~ 0.8)
2. âœ… ì‘ì€ ê°ì²´, ë¨¼ ê°ì²´ ì„±ëŠ¥ì´ ë‚˜ì¨
3. âœ… ê¸°ì¡´ class weightingìœ¼ë¡œ ë¶ˆì¶©ë¶„
4. âœ… ê³„ì‚° ìì›ì— ì—¬ìœ ê°€ ìˆìŒ

**NO, ë‹¤ìŒ ê²½ìš° ë‚˜ì¤‘ì—:**
1. âŒ ì•„ì§ ê¸°ë³¸ class weighting ì•ˆ í•´ë´„ â†’ ë¨¼ì € ì‹œë„
2. âŒ Combined Lossë„ ì•ˆ í•´ë´„ â†’ ë¨¼ì € ì‹œë„
3. âŒ ê³„ì‚° ìì›ì´ ë¶€ì¡± â†’ ë” ê°„ë‹¨í•œ ë°©ë²• ë¨¼ì €
4. âŒ ë¹ ë¥¸ ì‹¤í—˜ ë°˜ë³µì´ í•„ìš” â†’ êµ¬í˜„ ë³µì¡ë„ ë¶€ë‹´

---

## ğŸ“‹ ì ìš© ìˆœì„œ ì œì•ˆ

```
1ë‹¨ê³„: Combined Loss + Class Weights (ìš°ì„ !) ğŸš€
   â””â”€ êµ¬í˜„ ê°„ë‹¨, ì¦‰ì‹œ íš¨ê³¼, ê²€ì¦ë¨

2ë‹¨ê³„: ê²°ê³¼ ë¶„ì„
   â””â”€ ì—¬ì „íˆ íŠ¹ì • ìƒí™©ì—ì„œ ì„±ëŠ¥ ë‚˜ìœê°€?
   â””â”€ ì‘ì€ ê°ì²´, ë¨¼ ê°ì²´ê°€ ë¬¸ì œì¸ê°€?

3ë‹¨ê³„: Subclassified Loss ì‹œë„
   â””â”€ ë‹¨ìˆœ ë²„ì „ (num_subclasses=2)ë¶€í„°
   â””â”€ ì ì§„ì ìœ¼ë¡œ ë³µì¡ë„ ì¦ê°€

4ë‹¨ê³„: ìµœì í™”
   â””â”€ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
   â””â”€ í´ë˜ìŠ¤ë³„ ì„œë¸Œí´ë˜ìŠ¤ ìˆ˜ ì¡°ì •
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

**ë…¼ë¬¸**: OpenReviewì—ì„œ í™•ì¸ ê°€ëŠ¥
**ë°ì´í„°ì…‹**: SemanticKITTI, Cityscapesì—ì„œ ê²€ì¦
**í˜¸í™˜**: RangeNet++, KPRNet, PointRend, STDC, SegFormer ë“±ê³¼ í˜¸í™˜

---

**ê²°ë¡ **: 
- ë§¤ìš° í˜ì‹ ì ì´ê³  íš¨ê³¼ì ì¸ ë°©ë²•
- í•˜ì§€ë§Œ êµ¬í˜„ ë³µì¡ë„ê°€ ë†’ìŒ
- Combined Loss + Class Weightsë¥¼ ë¨¼ì € ì‹œë„í•œ í›„
- ì¶”ê°€ ê°œì„ ì´ í•„ìš”í•œ ê²½ìš° ê³ ë ¤ ì¶”ì²œ!

